# 第 7 章 数据采集 III：视频（长/短视频、驾驶/具身）

### 开篇段落

视频是连接视觉、语言与行动（VLA）最丰富、最动态的模态。它不仅包含静态图像信息，更蕴含着时间、因果、物理规律和交互意图，是训练能够理解并与真实世界交互的模型的终极数据源。本章的目标是构建一个可扩展、合规且成本可控的 **PB 级 (Petabyte)** 视频数据采集管道，以满足自动驾驶、具身智能和通用多模态场景的严苛需求。我们将深入探讨从合规采集（如 YouTube）、处理**多摄像头环视数据流**的复杂细节，到大规模存储架构与成本优化的全链路实操。完成本章后，您将能够设计、预算并实施一个足以支撑 10T token 级别训练的视频数据基础设施，为后续的模型训练奠定坚不可摧的数据基石。本章的关键产出是 **[里程碑 W5]**：完成视频数据采集 MVP 流程，并冻结基于量化分析的大规模存储与搬运成本预算方案。

### 文字论述

#### 7.1 合规采集：优先官方 API、尊重 robots.txt/ToS

在数据驱动的时代，合规性不是可选项，而是项目的生命线。任何捷径都可能导致数据资产作废、项目停滞甚至法律诉讼。

*   **官方 API 优先：以 YouTube Data API v3 为例**
    *   **工作机制**: 该 API 提供对 YouTube 资源的结构化访问，包括视频、频道、播放列表等。关键在于它返回的是**元数据**（标题、描述、标签、字幕可用性、分类 ID、许可类型等），而非视频文件本身。您可以使用这些元数据来筛选符合条件的视频，然后使用 `youtube-dl` 或其分叉 `yt-dlp` 等工具，在遵守服务条款的前提下进行下载
    *   **配额管理 (Quota Management)**:
        *   **成本**: API 调用并非免费，而是消耗配额点数。一个简单的搜索请求 (`search.list`) 消耗 100 点，而一个获取视频详情的请求 (`videos.list`) 消耗 1 点。
        *   **限制**: 一个 Google Cloud 项目默认每日配额为 10,000 点。这对于大规模采集是远远不够的。
        *   **扩展策略**: 必须设计一个**配额池系统**。注册多个 Google Cloud 项目，每个项目获取独立的 API 密钥。构建一个中心化的服务，轮询使用这些密钥，并监控每个密钥的配额余量，避免超限。当需要爬取数百万视频的元数据时，这套系统是必不可少的。
    *   **许可过滤**: API 返回的 `video.status.license` 字段至关重要。务必优先选择值为 `creativeCommon` 的视频，这类视频通常允许重用。对于标准的 `youtube` 许可，法务团队需要介入评估其在模型训练场景下的“合理使用”（Fair Use）边界。

*   **尊重 `robots.txt` 和服务条款 (ToS)**
    *   `robots.txt` 是君子协定，但它清晰地表明了网站所有者的意图。任何生产级的爬虫系统都必须内置一个 `robots.txt` 解析器，在访问任何 URL 之前检查规则。
    *   服务条款 (ToS) 是具有法律约束力的文档。其中通常包含关于自动化访问（“scraping”）的条款。**Rule-of-Thumb: 投入数小时让工程师和法务一起阅读 ToS，远比未来花费数月应对法律问题要划算。**

*   **数据溯源与合规日志 (Data Provenance)**
    *   对于下载的每一个视频，必须在元数据数据库中记录：
        *   原始 URL
        *   下载时间戳
        *   所使用的 API 密钥
        *   视频的许可类型
        *   视频所有者/频道信息
    *   这个日志不仅用于合规审计，也用于未来的数据清洗和去偏。

#### 7.2 多摄环视：6-camera 480p@12 Hz 时序同步、标定与外参/内参治理

自动驶场景的数据质量直接由传感器的同步与标定精度决定。一个微小的时空错位，在高速行驶中就可能放大为致命的决策错误。

*   **数据流带宽与存储的量化分析**:
    *   **规格**: 6 摄像头 x 640x480 分辨率 x 12 Hz 帧率 x 3 通道 (RGB8)。
    *   **原始码流**: `6 * 640 * 480 * 12 * 3 bytes/sec ≈ 66.4 MB/s` 或 `531 Mbps`。
    *   **一小时数据量（原始）**: `66.4 MB/s * 3600 s/hr ≈ 239 GB`。
    *   **压缩后码流**: 采用 H.265 (HEVC) 编码，目标是保持视觉质量，码率可以压缩到原始的 1-2%。
        | 编码方式 | 单路码率 (估算) | 6路总码率 (估算) | 一小时数据量 |
        | :--- | :--- | :--- | :--- |
        | 原始 (Uncompressed) | 88.5 Mbps | 531 Mbps | ~239 GB |
        | H.264 (高质量) | 2 Mbps | 12 Mbps | ~5.4 GB |
        | **H.265 (推荐)** | **1.2 Mbps** | **7.2 Mbps** | **~3.2 GB** |
    *   **结论**: 压缩是必须的，但选择何种压缩参数需要在存成本和解码开销之间做权衡。

*   **时序同步 (Temporal Synchronization)**:
    *   **挑战**: 硬件时钟的物理特性导致其会产生漂移。即使初始同步，在数小时后，不同传感器的时钟可能产生数十毫秒的偏差。
    *   **解决方案层级**:
        1.  **硬件同步 (最佳)**: 使用 **PTP (Precision Time Protocol)** 或 **GPS 脉冲秒 (PPS)** 信号，将所有传感器的时钟物理锁定到一个主时钟。可以实现亚毫秒级的同步精度。这是生产级自动驾驶数据采集车的标配。
        2.  **软件同步 (次优)**: 若无硬件同步，所有传感器数据都必须打上由同一台高精度时钟（如连接了 NTP 服务器的采集主机）生成的时间戳。尽管无法纠正传感器内部的触发延迟，但这能保证数据记录层面的对齐。
    *   **Rule-of-Thumb**: **可接受的同步误差不应超过半个采样周期**。对于 12 Hz 的摄像头（周期 83ms），同步误差应远小于 40ms，业界目标通常是 **< 1ms**。

*   **标定与内外参治理 (Calibration Governance)**:
    *   这是一个系统工程，而不只是一次性的测量。
    *   **内参 (Intrinsics)**: `K = [[fx, 0, cx], [0, fy, cy], [0, 0, 1]]` + 畸变系数 `[k1, k2, p1, p2, k3]`。
    *   **外参 (Extrinsics)**: 从相机坐标系到车辆坐标系的 4x4 变换矩阵 `T_vehicle_cam`。
    *   **治理系统**: 必须建立一个数据库，其主键至少包含 `(Vehicle_ID, Sensor_ID, Timestamp_Start, Timestamp_End)`，值为对应的内外参文件路径或内容。任何一段视频数据，都可以通过其车辆 ID 和时间戳，**唯一、确定地**查询到当时生效的标定参数。车辆每次维护或传感器更换后，都必须触发新的标定流程并更新该数据库。

```ascii
      World Frame (e.g., Map)
           | T_world_vehicle (from GPS/IMU fusion)
           v
      Vehicle Frame (Ego) --- T_vehicle_cam_front ---> Camera Frame (Front)
           |
           +-- T_vehicle_cam_left ---> Camera Frame (Left)
           |
           ... (and so on for all 6 cameras)

图 7.1: 坐标系变换关系。模型需要利用这些外参(T)将不同视角的像素投影到统一的3D空间。
```

#### 7.3 帧采样与镜头检测；字幕/ASR 对齐

原始视频帧是高度冗余的。智能采样不仅节省存储和计算，还能让模型更关注动态变化。

*   **高级帧采样策略**:
    *   **基于光流的采样**: 计算连续帧之间的光流场。当平均光流幅值超过一个阈值时（表示场景或相机在运动），提高采样率；当光流较小时（如等红灯），降低采样率。
    *   **基于内容变化的采样**: 提取每帧的特征向量（例如用一个预训练的 ViT）。当新一帧的特征向量与上一采样帧的余弦相似度低于某个阈值（如 0.95）时，保留该帧。
*   **镜头检测 (Shot Boundary Detection)**:
    *   对于长视频（如公开课、电影），理解场景切换至关重要。
    *   **算法**: 简单方法是计算连续帧的颜色直方图差异。更鲁棒的方法是使用基于深度学习的模型，如 TransNetV2，它可以同时检测硬切（hard cuts）和渐变（gradual transitions）等效果。
    *   **应用**: 将视频切分成语义连贯的镜头片段，每个片段可以被视为一个独立的训练样本，并可以被一个句子或段落描述。

#### 7.4 驾驶/具身专用：传感器同步（RGB、深度、IMU、CAN、地图）

VLA 模型需要理解“我（ego）做了什么导致了什么结果”，这要求将视觉观测与自身行动及物理状态紧密关联。

*   **核心传感器数据流及其作用**:
    | 传感器 | 典型频率 | 数据类型 | 关键作用 | 同步挑战 |
    | :--- | :--- | :--- | :--- | :--- |
    | **IMU** | 100-1000 Hz| 加速度, 角速度 | 提供高频自我运动估计，预测物理动态 | 频率最高，需降采样或积分与低频数据对齐 |
    | **CAN Bus**| 10-100 Hz | 方向盘转角, 速, 油门/刹车 | 提供精确的 **Action 监督信号** | 信号有延迟和抖动，需要滤波 |
    | **GPS** | 1-10 Hz | 经纬度, 海拔, 速度 | 提供全局定位 | 频率低，信号可能在城市峡谷中丢失 |
    | **LiDAR** | 10-20 Hz | 3D 点云 | 提供精确的深度和几何信息 | 数据量大，与相机像素的投影对齐复杂 |
    | **HD Map** | - | 矢量数据 | 提供场景先验（车道线、交通灯位置） | 将车辆定位到地图上需要高精度定位 |

*   **数据融合与格式**:
    *   所有传感器数据流最终需要被解析并存储到一个统一的、按时间戳索引的格式中。常用的解决方案包括 **ROS bags** 的后处理、Apache **Parquet** 文件或 **HDF5** 文件。
    *   **Rule-of-Thumb**: **为每个驾驶/具身数据序列（log）创建一个“时间轴”**。将所有传感器事件都视为这个时间轴上的点。在为模型准备数据时，以摄像头帧的时间戳为中心，在时间轴上查询前后一小段时间窗口内的其他传感器读数，通过插值（线性插值、SLERP球面线性插值用于姿态）或最近邻匹配，来构建一个**多模态同步帧**。

#### 7.5 大规模存储与搬运成本：冷/热层、对象存储与数据搬迁

存储和数据移动是继算力之后的第二大成本中心。一个 10 PB 的数据集，如果管理不善，每月可能产生数万甚至数十万美元的费用。

*   **存储分层与成本建模**:
    | 存储层 | 用途 | 访问延迟 | 存储成本 (估算) | 数据读取成本 (估算) |
    | :--- | :--- | :--- | :--- | :--- |
    | **冷存 (Cold)** | 原始数据归档 | 小时级 | ~$1 / TB / 月 | ~$0.02 / GB |
    | **温存 (Warm/Object)** | 清洗/处理后数据 | 毫秒级 | ~$23 / TB / 月 | ~$0.0004 / 1k req |
    | **热存 (Hot/FS)** | 训练缓存 | 微秒级 | >$100 / TB / 月 | - |
    *   **案例**: 10 PB 原始数据存放在冷存，每月成本约 $10k。处理后生成 1 PB 的训练数据放在温存，每成本约 $23k。训练时，需要一个 100 TB 的热存缓存层，每月成本约 $10k。**总计每月存储成本可达 $40k-$50k。**

*   **数据搬运成本 (Egress Cost)**:
    *   云服务商对**从其网络传出数据**收费，通常在 $0.05 - $0.09 / GB 之间。
    *   **灾难场景**: 假设一个 100TB 的数据集被误放在 `us-east-1` 区域，而训练集群在 `us-west-2`。仅将数据搬运一次的成本就高达 `100 * 1024 * $0.02 = $2048`（区域间传输）。如果数据加载器频繁跨区读取，成本将是天文数字。
    *   **铁律**: **“计算必须靠近数据”**。预处理、训练、评测的所有计算资源，都必须部署在温存/对象存储所在的同一个云区域。

*   **[里程碑 W5] 交付物**: 一份详细的成本分析报告，包含：
    1.  总数据量估算（原始、处理后）。
    2.  各层存储的容量规划和月度成本。
    3.  数据预处理 pipeline 的计算实例成本。
    4.  数据加载带宽需求分析和网络成本预估。
    5.  最终形成一个清晰的、可供财务审批的**月度数据基础设施预算**。

#### 7.6 去重与相似片段合并；码率/编解码与归档策略

在 PB 级数据中，重复和冗余是巨大的浪费。

*   **多层次去重**:
    1.  **文件哈希去重**: 使用 SHA-256 对原始下载文件去重，这是最快的第一步。
    2.  **感知哈希 (Perceptual Hashing)**: 将视频解码成帧，对关键帧计算 pHash/dHash/aHash。这些哈希对轻微的图像编辑（亮度、对比度、水印）不敏感。通过比较哈希的汉明距离来判断相似性。
    3.  **特征向量去重 (最强)**: 使用一个强大的预训练模型（如 VideoMAE, CLIP）为视频片段提取高维特征向量。然后，使用 **FAISS** 或 **ScaNN** 等库构建一个近似最近邻（ANN）索引。通过查询这个索引，可以高效地找到语义上高度相似的视频片段（例如，不同用户上传的同一段新闻报道），后只保留质量最高的一个版本。
*   **归档与压缩策略**:
    *   **编解码器选择**: 对于永久归档，计算成本可以接受，应优先选择压缩率最高的编解码器。**AV1** 是目前的主流选择，相比 H.265 能再节省约 20-30% 的空间，但编码速度慢得多。
    *   **FFmpeg 归档命令示例 (H.265)**:
        `ffmpeg -i input.mp4 -c:v libx265 -preset slow -crf 28 -c:a aac -b:a 128k output_archive.mp4`
        *   `-preset slow`: 投入更多计算换取更好的压缩。
        *   `-crf 28`: Constant Rate Factor，一个质量参数，数值越大压缩率越高但质量越低。28 是一个适用于 480p 视频的合理起点。

### 本章小结

本章深入剖析了构建一个生产级、PB 规模视频数据管道的全过程，远超简单的脚本下载。
*   **合规与溯源是生命线**：通过 API 配额管理和严格的日志记录，确保每份数据的来源清晰、使用合规。
*   **时空精度定义数据质量**：对自动驾驶和具身场景，**亚毫秒级时序同步**和**严格的标定治理**是数据价值的核心，绝不可妥协。
*   **成本是架构的核心驱动力**：基于**分层存储**和**计算靠近数据**的原则进行量化成本建模，是项目成功的关键财务保障。
*   **智能处理是效率的放大器**：通过高级采样、特征去重和高效编码，我们从原始数据洪流中提炼出高价值、低冗余的训练集。
*   **多传感器融合是通往物理世界的桥梁**：将视频与 IMU、CAN 等数据流在统一的时间轴上对齐，是训练能够理解并执行物理行动的 VLA 模型的前提。

### 常见陷阱与错误 (Gotchas)

1.  **“标定一次，终身使用”**：认为车辆或机器人的标定参数是静态的。物理世界的颠簸、维修、热胀冷缩都会导致参数漂移。没有定期的重新标定和版本管理，会导致模型训练在“垃圾”的几何数据上。
2.  **元数据地狱 (Metadata Hell)**：关注视频文件本身，而忽略了元数据的管理。当你有数十亿个视频切片时，如何快速查询“所有在雨天、夜晚、包含左转弯的、来自 A 车辆的片段”就成了一个复杂的数据库工程问题。早期就需要设计好元数据的 schema 和索引。
3.  **忽略解码成本**：在训练循环中，视频解码可能成为 CPU 瓶颈，导致昂贵的 GPU 处于空闲等待状态（starvation）。数据预处理应尽可能将视频解码为图像帧（或提取特征），并以易于直接读取的格式（如序列化的 Tensor）存储，以最大化 GPU 利用率。
4.  **采集的“幸存者偏差”**：采集的驾驶数据大部分是车辆正常行驶的片段，充满了“直行”和“跟车”。模型在这种数据上训练后，对于紧急刹车、突然变道等罕见但关键的“corner cases”表现极差。数据采集策略必须主动去挖掘和平衡这些长尾场景。
5.  **小文件灾难**：将每个视频切片（可能只有几秒）存成一个独立的小文件，在对象存储或分布式文件系统上会导致严重的性能问题（元数据开销巨大）。应将数千个小样本打包成一个大的顺序文件（如 TAR 文件），以提高 IO 效率。这正是 WebDataset 等库的核心思想。

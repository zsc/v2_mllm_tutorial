# 第 9 章 数据采集 V：3D（程序化优先）

## 开篇段落

本章将深入探讨多模态大模型预训练中一个至关重要但极具挑战的领域：**三维（3D）数据的采集与处理**。对于自动驾驶、具身智能和高级人机交互等场景，模型若要真正理解并与物理世界互动，就必须超越 2D 像素的局限，掌握物体的几何形状、空间关系、物理属性与拓扑结构。3D 数据的高维度和复杂性，使其采集与表征成为构建高级 VLA (Vision-Language-Action) 模型的关键瓶颈。本章的目标是建立一套高效、可扩展且语义丰富的 3D 数据采集策略，其核心原则是颠覆性的——**“程序化优先” (Programmatic-First)**。我们将优先采集能够生成 3D 模型的脚本与参数化描述，其次是结构化的文本格式，最后才是传统的静态网格文件。这种策略的本质，是从学习“物体长什么样”跃迁到学习“物体是如何被构建的”，从而让模型不仅能识别，更能推理其背后的设计意图与因果逻辑。

---

## 9.1 Blender/CAD 脚本：程序化几何与参数化场景

我们 3D 数据策略的顶层是程序化内容，即能够通过代码或脚本生成 3D 场景的源文件。这在概念上等同于代码预训练中优先选择人类可读的、逻辑清晰的源代码，而非编译后的、信息大量丢失的二进制文件。

*   **核心思想**：我们采集的不是静态的 `.obj` 或 `.stl` 文件，而是生成这些文件的 **“可执行配方” (Executable Recipes)**。这些配方本身就是一种极其紧凑且富含逻辑的语言。

    *   **示例：Blender Python API**
        ```python
        # 一个简单的程序化脚本示例
        import bpy
        
        # 清理场景
        bpy.ops.object.select_all(action='SELECT')
        bpy.ops.object.delete()
        
        # 创建一个立方体并参数化修改
        bpy.ops.mesh.primitive_cube_add(size=2, location=(0, 0, 1))
        cube = bpy.context.object
        cube.scale = (1, 2, 0.5) # 参数化控制尺寸
        
        # 添加一个修改器（如倒角），体现程序化逻辑
        bpy.ops.object.modifier_add(type='BEVEL')
        cube.modifiers["Bevel"].width = 0.1
        cube.modifiers["Bevel"].segments = 3
        ```
    *   **示例：OpenSCAD**
        ```openscad
        // 描述性几何语言
        module rounded_box(size, radius) {
          hull() {
            for (x = [0,1], y = [0,1], z = [0,1]) {
              translate([
                x * (size[0] - 2*radius) + radius, 
                y * (size[1] - 2*radius) + radius, 
                z * (size[2] - 2*radius) + radius
              ]) sphere(r=radius);
            }
          }
        }
        rounded_box([20, 30, 10], 2); // 参数化调用
        ```

*   **程序化数据的独特优势**：
    1.  **极高的信息密度与压缩率**：几 KB 的脚本可以定义一个极其复杂的场景，其信息熵远高于渲染后数 MB 甚至数 GB 的网格文件。这是最极致的“压缩”。
    2.  **可控的、无限的数据增强**：通过程序化地扫描脚本中的参数（尺寸、分段数、随机种子），我们可以生成几乎无限的、多样且逻辑一致的 3D 样本，是解决 3D 数据稀疏性问题的根本手段。
    3.  **学习因果与逻辑推理**：模型可以直接学习从“设计意图”（代码逻辑）到“最终形态”（渲染结果）的映射。这使得模型有望回答 "如果把这个桌腿改短 10 厘米会怎么样？" 这类反事实和因果推理问题。
    4.  **组合性与泛化**：模型可以学习代码中的函数、模块等抽象概念，并可能在推理时行新的组合，生成训练集中未见过的新颖结构，展现出强大的组合泛化能力。
    5.  **天然的版本化与可追溯性**：脚本文件是文本，可以轻松地使用 Git 等工具进行版本控制，追踪每一次修改，这对于构建可复现、可审计的数据集至关重要。

*   **数据来源与采集策略**：
    *   **代码托管平台**：在 GitHub、GitLab 等平台大规模搜索使用 `import bpy` (Blender)、`openscad`、`cadquery` 等关键词的公开项目。
    *   **3D 模型社区**：Thingiverse、Printables、MyMiniFactory 等社区，许多创作者会分享 `.scad`, `.f3d` (Fusion 360) 等源文件。
    *   **学术与仿真数据集**：机器人学（如 ShapeNet 的部分子集）、物理仿真领域的 benchmark 通常包含程序化生成的场景描述文件。

*   **生产级处理流程**：
    1.  **采集与元数据关联**：抓取脚本文件，并一同保存其所有相关元数据，如项目 `README.md`、文本描述许可证文件（`LICENSE`）、代码注释。
    2.  **依赖分析与环境打包**：分析脚本的依赖项（如特定的 Blender 版本、Python 库）。为不同类型的脚本创建标准化的、隔离的 Docker 执行环境。
    3.  **安全沙箱执行与渲染**：在**无网络、文件系统只读**的沙箱容器中执行脚本。脚本的输出被重定向，生成标准化的 3D 格式（如 `.glTF`）和多角度渲染图（如 12 个标准视角的 2D 图像）。**这是安全红线，严禁在生产环境直接执行未知来源的脚本**。
    4.  **结构化数据对封装**：将所有产物封装成一个结构化的数据单元，例如一个 JSON 对象：
        ```json
        {
          "id": "unique_id_123",
          "source_script": "...", // 原始脚本内容
          "language": "blender_python",
          "text_description": "A 3D model of a rounded box...",
          "rendered_mesh_path": "s3://bucket/meshes/123.gltf",
          "rendered_views_path": ["s3://.../view_0.png", ...],
          "parameters": {"size": [20, 30, 10], "radius": 2}, // 如果可提取
          "license": "MIT"
        }
        ```

> **经验法则 (Rule-of-Thumb)**：
> 将每个程序化 3D 脚本视为一个**可调用的函数**：`f(params) -> Geometry`。我们的目标是让模型学习这个函数 `f` 本身，而不仅仅是它在某些特定 `params` 下的输出。数据集的质量取决于覆盖的 `f` 的多样性和 `params` 的广度。

---

## 9.2 X3D-类文本结构化格式：层级/拓扑/材质的文本化表示

当无法获取程序化脚本时，我们的第二优先选择是基于文本的、描述场景图（scene graph）的结构化格式。X3D、VRML、以及行业内越来越重要的 USD (Universal Scene Description) 和 glTF 的 JSON 部分，都属于此类。它们描述了场景的“静态构成”，而非“动态生成过程”。

*   **核心思想**：这些格式以类似 XML 或 JSON 的层级结构，声明式地定义一个 3D 场景的所有元素及其关系，包括：
    *   **节点 (Node)**：几何体、光源、相机、分组节点。
    *   **变换 (Transform)**：每个节点的位置、旋转、缩放，形成父子层级关系。
    *   **属性 (Attribute)**：材质（颜色、粗糙度）、几何参数（球体半径）、灯光强度等。

*   **优势**：
    *   **可直接作为文本输入**：作为纯文本，可以直接被模型的文本 tokenizer 处理。模型可以像解析 HTML DOM 树或 JSON 对象一样，学习理解 3D 场景的结构化语法。
    *   **保留高级语义结构**：场景的层级关系（例如，`车轮` 是 `车轴` 的子节点，`车轴` 是 `底盘` 的子节点）、有意义的对象命名 (`DEF="LeftFrontWheel"`)、材质属性等高级语义被完整保留，这是 `.obj` 等格式完全不具备的。
    *   **人类可读与可调试**：便于工程师进行数据样本的人工检查和调试。

*   **ASCII 图示：一个更丰富的 X3D 场景图结构**
    ```xml
    <X3D profile='Immersive'>
      <Scene>
        <!-- 定义一个可复用的红色材质 -->
        <Appearance DEF='RedAppearance'>
          <Material diffuseColor='1 0 0' specularColor='0.5 0.5 0.5'></Material>
        </Appearance>
        
        <!-- 车辆底盘 -->
        <Transform DEF='ChassisTransform' translation='0 0.5 0'>
          <Shape>
            <Appearance USE='RedAppearance'></Appearance>
            <Box size='1.8 0.4 4'></Box>
          </Shape>
          
          <!-- 前轴，是底盘的子节点 -->
          <Transform DEF='FrontAxle' translation='0 0 -1.5'>
            <!-- 左前轮，是前轴的子节点 -->
            <Transform translation='-1 0 0'>
              <Shape> ... <Cylinder radius='0.4' height='0.2'></Cylinder> ... </Shape>
            </Transform>
            <!-- 右前轮 -->
            <Transform translation='1 0 0'>
              ...
            </Transform>
          </Transform>
        </Transform>
      </Scene>
    </X3D>
    ```

*   **处理与 Tokenization**：
    1.  **解析与验证**：使用标准库（如 `lxml` for XML, `orjson` for JSON）解析文件，验证其是否符合格式规范。
    2.  **线性化 (Linearization)**：将树状结构转换为一个 token 序列。常用方法是**深度优先遍历 (Pre-order Traversal)**，并引入特殊 token 来表示结构：
        *   ` <TRANSFORM_START> `
        *   ` translation='0 0.5 0' `
        *   ` <SHAPE_START> `
        *   ...
        *   ` <SHAPE_END> `
        *   ` <TRANSFORM_END> `
        这样，Transformer 的注意力机制就能自然地捕捉到层级依赖关系。
    3.  **数值处理**：将 `translation='0 0.5 0'` 这样的属性值中的数字进行适当的分箱或直接作为字符串处理，这取决于 tokenizer 的设计。

> **[里程碑] W6: 3D数据采集与预处理管道原型完成**
> 此时，我们应完成针对程序化脚本和 X3D/USD 类文本格式的数据采集、安全执行/解析、规整化和封装的自动化管道原型。产出的数据应是结构化的，可直接供后续的 tokenizer 和数据加载器使用。

---

## 9.3 .obj 回落 与互操作；必要时扩展到 .ply/.pcd

在无法获得程序化或结构化源文件的情况下，我们才回落到采集最常见的传统 3D 网格格式，如 `.obj`、`.stl`。这类文件本质上是“几何的快照”，是“顶点和面的扁平列表”，丢失了绝大部分高层语义信息。

*   **核心思想**：将 `.obj` 文件视为一种低级的、需要专门编码的几何表征。直接将其作为文本送入模型是低效且错误的。

*   **为什么直接 Tokenize `.obj` 是个坏主意**：
    *   **词汇表爆炸**：`v 1.234567 0.987654 0.543210` 这样一行中，浮点数的变化是无穷的，会导致 BPE 词表被大量无意义的数字片段污染。
    *   **语义模糊**：Tokenizer 会将 `v`、`1.23`、`456` 等分割为独立的 token，完全破坏了 `(x, y, z)` 作为一个坐标向量的结构。
    *   **列过长**：一个中等复杂度的模型可能有数百万个顶点，生成的 token 序列长度将远超现有 Transformer 的处理能力。

*   **推荐的处理与 Tokenization 方案：量化与序列化**
    1.  **解析与规整**：使用 `trimesh` 等库读取顶点和面列表。然后执行严格的**规整化**（详见 9.5 节），包括将模型移至原点、缩放到单位立方体内。
    2.  **顶点量化 (Vertex Quantization)**：
        *   将单位立方体 `[-1, 1]^3` 划分为一个离散的 3D 网格，例如 `1024x1024x1024`。
        *   每个顶点的浮点坐标 `(x, y, z)` 被映射到离散的整数坐标 `(ix, iy, iz)`，其中 `ix, iy, iz` 在 `[0, 1023]` 范围内。
        *   `ix = round((x + 1) / 2 * 1023)`
    3.  **序列化 (Serialization)**：
        *   为每个坐标轴的 `1024` 个离散位置分配专门的 token，例如词表中有 `X_0, ..., X_1023`, `Y_0, ..., Y_1023`, `Z_0, ..., Z_1023`。
        *   一个顶点 `(ix, iy, iz)` 被表为三个 token 序列 `<X_ix, Y_iy, Z_iz>`。
        *   引入特殊 token，如 `<VERTEX_START>`, `<FACE_START>`。
        *   整个 `.obj` 文件被转换为一个 token 序列，如：`<VERTEX_START> X_512 Y_600 Z_700 <VERTEX_START> ... <FACE_START> 1 4 3 <FACE_START> ...`
    4.  **顶点排序**：为了使同一几何体的 token 序列表示具有唯一性，可以对顶点进行规范排序，例如按照 Morton code (Z-order curve) 排序，以增强空间局部性。

*   **处理点云 (.ply, .pcd)**：对于自动驾驶场景中的 LiDAR 点云，处理流程类似，但只包含顶点量化与序列化步骤，没有“面”的信息。

> **经验法则 (Rule-of-Thumb)**：
> `.obj` 数据的预处理目标是：将连续的、无序的几何信息，转换为离散的、具有规范顺序的 token 序列，使其“语言化”以便 Transformer 理解。这个过程是有损的，量化精度（如 10-bit 对应 1024 个 bin）是在保真度和序列长度之间的权衡。

---

## 9.4 3D-文本/视频对齐策略与标定元数据

孤立的 3D 数据价值有限，其核心价值在于与其他模态的**精确对齐**。

*   **3D-文本对齐**：
    *   **显式对齐**：从 Sketchfab、TurboSquid 等平台抓取模型时，必须同时保存其标题、详细描述、用户标签、分类、评论等所有相关的文本信息。这些文本是高质量的监督信号。
    *   **隐式对齐**：对于程序化脚本，代码中的变量名（如 `wheel_radius`）、函数名、代码注释本身就是最精确、最细粒度的文本描述。

*   **3D-视频/图像对齐（自动驾驶/具身核心）**：
    *   **关键要素**：这需要采集包含已知 3D 对象的真实世界或高保真仿真视频，并附带精确的**时序同步的传感器标定元数据**。
    *   **相机内参 (Intrinsics)**：矩阵 $K$，描述了相机的内部光学特性（焦距 $f_x, f_y$，主点 $c_x, c_y$）。
    *   **相机外参 (Extrinsics)**：矩阵 $[R|t]$，描述了相机坐标系相对于世界坐标系（或车辆坐标系）的旋转 $R$ 和平移 $t$。
    *   **投影关系**：利用这些参数，我们可以将世界坐标系中的一个 3D 点 $X_{world}$ 投影到图像的 2D 像素坐标 $p_{image}$：
        $ p_{image} = K [R|t] X_{world} $
        这个公式是实现 3D 模型与 2D 视频像素级对齐的数学基础。
    *   **数据点最终形态**：一个理想的对齐数据点是一个复杂的元组：
        ```
        (
          video_frames_t,                // t 时刻的多摄像头图像 (e.g., 6-cam)
          lidar_point_cloud_t,           // t 时刻的 LiDAR 点云
          imu_data_t,                    // t 时刻的 IMU 数据
          can_bus_data_t,                // t 时刻的车辆状态 (速度, 转向角)
          object_3d_annotations: [
            {
              "3d_model_id": "cad_model_car_01", // 关联到我们的 3D 模型库
              "world_pose_t": [R|t],           // 该物体在 t 时刻的世位姿
              "text_description": "A red sedan turning left"
            }, ...
          ],
          camera_intrinsics_and_extrinsics // 所有相机的内外参
        )
        ```

---

## 9.5 3D 数据压缩、规整与重复检测

处理 TB 甚至 PB 级别的 3D 数据，需要工业级的 MLOps 流程来保证效率和质量。

*   **压缩 (Compression)**：
    *   **网格压缩**：对 `.obj`, `.glTF` 等格式，使用 Google Draco 算法进行压缩。Draco 专为 3D 网格设计，压缩率极高，同时支持有损和无损模式。
    *   **点云压缩**：使用专为点云设计的压缩方案或简单的 Zstd。
    *   **文本压缩**：程序化脚本和结构化文本文件使用 Zstandard (Zstd) 进行压缩，它在压缩率和解压速度上取得了很好的平衡。

*   **规整 (Normalization)**：这是保证模型训练稳定性的关键一步。所有 3D 数据在进入训练流程前，必须经过严格的自动化规整管道：
    1.  **坐标系统一**：强制所有模型转换为统一的坐标系（例如，Y 轴朝上，右手坐标系）。
    2.  **单位统一**：将所有单位转换为米。
    3.  **姿态规范化 (Canonical Orientation)**：通过主成分分析 (PCA) 计算顶点分布的主轴，将模型旋转到对齐坐标轴的规范姿态。这能大大减少模型需要学习的姿态方差。
    4.  **尺度统一**：将模型整体缩放，使其最长轴的长度为 1，并将其平移至坐标原点。原始的物理尺寸必须作为元数据保存。

*   **重复检测 (Deduplication)**：
    *   **基于文本/脚本**：对程序化脚本和结构化文本，使用 SimHash 或其他代码/文本去重算法。
    *   **基于几何**：这是一个难题，因为微小的顶点扰动就会导致文件哈希完全不同。
        1.  **规范化渲染**：将经过规整化的模型从多个标准视点（如正六面体的 6 个面中心、12 条棱的中点）渲染成深度图或轮廓图。
        2.  **图像哈**：计算这些 2D 渲染图的感知哈希（如 pHash, aHash）。
        3.  **相似度判断**：如果两个 3D 模型在多个视角的渲染图哈希值都非常接近，则将它们标记为近重复。这是一种计算成本较高但相对可靠的方法。

---

## 本章小结

本章系统性地阐述了一套面向大规模预训练的、“程序化优先”的 3D 数据采集与处理策略，旨在为模型提供超越表象的、结构化的三维世界知识。

1.  **采集优先级金字塔**：我们建立了 `程序化脚本 (Blender/CAD)` > `结构化文本 (X3D/USD)` > `传统网格 (.obj)` 的采集层次。这一策略的核心是从学习“结果”转向学习“过程与结构”。
2.  **差异化的处理策略**：针对不同类型的数据，我们设计了专门的处理与 Tokenization 方案。脚本和结构化文本被“语言化”，而传统网格则被“几何编码”为离散 token 序列。
3.  **对齐是核心价值**：3D 数据的力量在于与文本、视频等其他模态的精确对齐。我们强调了基于相机标定元数据实现 3D-2D 投影对齐的数学基础和工程实践。
4.  **工业级数据治理**：构建生产级 3D 数据集离不开严格的 MLOps 流程，包括高效压缩、关键的规整化（坐标系、尺度、姿态统一）以及基于几何感知的重复检测。

---

## 常见陷阱与错误 (Gotchas)

1.  **坐标系地狱 (Coordinate System Hell)**：这是 3D 数据处理中最常见且最致命的错误。Blender (Z-up), Unreal Engine (Z-up), Unity (Y-up), OpenGL (Y-up, right-handed), DirectX (Y-up, left-handed) 各不相同。必须在数据入口处建立一个单一、强制的规范坐标系转换管道，并配有单元测试。否则，模型将学到完全混乱和矛盾的空间关系。
2.  **尺度与单位混淆 (Scale & Unit Ambiguity)**：一个在文件中尺寸为 `1.0` 的物体，可能代表 1 毫米、1 厘米或 1 米。在规整化时，必须尽最大努力从元数据中恢复其真物理尺寸，并作为单独的特征输入给模型，否则模型无法建立对物理世界的正确认知。
3.  **危险的脚本执行 (Unsafe Script Execution)**：再次强调，从互联网上抓取的代码是潜在的安全威胁。执行脚本的沙箱环境必须是最小权限的，严格禁止网络访问和对宿主机文件系统的写操作。定期审计沙箱的逃逸漏洞。
4.  **拓扑错误与非流形网格 (Broken Topology & Non-Manifold Meshes)**：采集到的 `.obj` 文件常常包含破面、自相交、非流形边（一条边连接超过两个面）等问题。这些“脏”数据会破坏渲染、物理仿真和某些几何处理算法。预处理流程中必须集成自动化的网格修复工具（如 `PyMeshFix`）来清洗和校验网格的有效性。
5.  **规范化引入的对称性歧义 (Ambiguity in Canonicalization)**：对于高度对称的物体（如球体、立方体），基于 PCA 的规范化姿态可能不是唯一的，微小的噪声就可能导致其主轴方向在多个等价姿态间跳变。这会给模型带来不必要的学习噪声。需要设计更鲁棒的规范化算法或在训练中加入对称性数据增强来缓解此问题。

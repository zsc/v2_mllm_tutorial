<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="./">
    <title>[chapter17.md] 模型架构：Qwen‑式自回归 Transformer（Dense / 先进 MoE，早期融合）</title>
    <link rel="stylesheet" href="assets/style.css">
    <link rel="stylesheet" href="assets/highlight.css">
    <script src="assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors', 'ams']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors', '[tex]/ams']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>目录</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <div class="sidebar-search">
                <input type="text" id="sidebar-search-input" placeholder="搜索..." autocomplete="off">
            </div>
            <div id="tree-container">
                <nav class="tree-nav" role="tree">
                    <div class="tree-item " >
                        <a href="index.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">面向 Vision‑Language‑Action（VLA）、自动驾驶/具身与语音交互的多模态大模型预训练教程（公开版）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter1.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">[chapter1.md] 前言、范围与读者指南</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter2.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 2 章：全局时间线与里程碑（W0–W26）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter3.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第三章：需求拆解与系统能力画像（VLA / AD / 语音）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter4.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第四章：数据总体策略与 30T token 配额（多语多模）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter5.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第五章 数据采集 I：网页文本与代码（合规）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter6.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 6 章：数据采集 II：音频/语音（播客、公开课、语音数据集）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter7.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 7 章 数据采集 III：视频（长/短视频、驾驶/具身）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter8.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">[chapter8.md] 数据采集 IV：图像</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter9.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 9 章 数据采集 V：3D（程序化优先）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter10.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十章：数据治理与质量度量（跨模态）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter11.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 11 章 过滤与去脏：fastText 与小模型策略库</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter12.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 12 章：合成数据 I：教科书式文本/指令（Phi-3 风格）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter13.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十三章 合成数据 II：音频与语音</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter14.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 14 章 合成数据 III：视频与 VLA 自博弈（Agentic RL Self‑Play）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter15.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Tokenizer 设计：文本/音频/视频/图像/3D</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter16.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">[chapter16.md] 生成‑理解一体架构沿革</span>
                        </a>
                    </div>
                
                    <div class="tree-item active" >
                        <a href="chapter17.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">[chapter17.md] 模型架构：Qwen‑式自回归 Transformer（Dense / 先进 MoE，早期融合）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter18.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">[chapter19.md] 训练配方：从 1B 到 10B 的生产级方案</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter19.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">[chapter19.md] 训练配方：从 1B 到 10B 的生产级方案</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter20.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 20 章 蒸馏与教师模型：Gemma‑式 Logits 蒸馏及多模态知识迁移</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter21.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">[chapter21.md] 对齐与中期训练（Instruction/Mid-training/偏好）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter22.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 22 章：评测与基准（多模/多语/VLA/驾驶/语音）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter23.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">[chapter23.md] 成本、运维与 MLOps</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter24.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 24 章：交付与复现</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter25.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 25 章：安全、法律与合规</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter26.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">[chapter26.md] 项目管理与人员阵型：大型AI工程的“交响乐指挥法”</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter27.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">`[chapter27.md]` 常见陷阱与故障排查</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter28.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">附录 A：配置与脚本模板（可复制）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="appendixA.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">附录 A：配置与脚本模板（可复制）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="CLAUDE.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Untitled</span>
                        </a>
                    </div>
                </nav>
            </div>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="chapter17md-qwen-transformerdense-moe">[chapter17.md] 模型架构：Qwen‑式自回归 Transformer（Dense / 先进 MoE，早期融合）</h1>
<h3 id="1">1. 开篇段落</h3>
<p>在第 16 章，我们穿越了生成-理解一体架构的演化历史，从理论层面探讨了统一多模态模型的可能性。现在，我们将从高远的理论天空降落到坚实的工程地面。本章是整个项目的技术心脏，我们将在这里绘制出 VLA 大模型的精确蓝图。这不仅是一份参数列表，更是我们团队关于模型能力、计算预算和实现路径的核心共识。本章的学习目标是：深刻理解为何选择 Qwen 式自回归 Transformer 作为统一骨架；精通 1B Dense 与 10B MoE 两档规模的架构细节、参数权衡与设计哲；并掌握多模态早期融合、<strong>先进 MoE</strong> 路由机制、<strong>Perceiver 式视觉压缩</strong>以及 VLA 动作头等关键模块的实现原理。本章的产出——冻结的架构方案，将成为指导后续所有数据处理、基建搭建和训练策略的“根本大法”。<strong>[里程碑 W7]</strong> 的达成，标志着我们从“想做什么”进入了“具体怎么做”的阶段。</p>
<h3 id="2">2. 文字论述</h3>
<h4 id="171">17.1 核心思想：以语言为中心的统一生成框架</h4>
<p>我们的终极目标是构建一个能够理解复杂的、动态的多模态世界，并能在其中自主决策与行动的智能体。实现这一目标的最佳路径，是采用一个具有极致扩展性的统一框架。我们坚信，<strong>自回归（Autoregressive, AR）Transformer</strong> 是当前实现该目标的最优解。</p>
<p>其核心哲学在于“<strong>万物皆可 Token 化</strong>”。无论是“你好”这两个汉字、一段语音的声学特征、一幅图像的视觉概念，还是一个“方向盘左转 15 度”的驾指令，都可以被编码为离散的 token 序列。一旦完成这一转换，所有看似迥异的任务都统一为同一个、极其简单的目标：</p>
<p>$P(\mathbf{x}) = \prod_{i=1}^{N} P(x_i | x_{&lt;i}, \mathbf{c})$</p>
<p>其中，$\mathbf{c}$ 是由文本、音频、视频、3D 等任意模态组成的庞大上下文，而 $\mathbf{x}$ 则是模型需要生成的目标序列（一段描述、一个回答、一连串动作指令）。这种范式的优雅之处在于：</p>
<ol>
<li><strong>生成与理解一体</strong>：模型在预测下一个 token 时，必须深刻“理解”之前的多模态上下文。因此，强大的生成能力内生了强大的理解能力。</li>
<li><strong>任务无关性</strong>：VQA、图像描述、ASR、自动驾驶决策……所有任务都被拉平到同一个自回归预测的框架下，无需为每个任务设计复杂的独立模型头或损失函数。</li>
<li><strong>无缝扩展</strong>：未来若要加入新的模态（如雷达、触觉），我们只需设计相应的 Tokenizer 和投影器，将其融入下文 $\mathbf{c}$ 即可，主干网络无需改动。</li>
</ol>
<p>我们选择 <strong>Qwen 系列模型</strong>的架构作为基座，因为它集成了近年来被广泛验证为高效且稳定的设计“全家桶”：<strong>RMSNorm</strong> 提供了比 LayerNorm 更优的稳定性和计算效率；<strong>SwiGLU</strong> 激活函数在 FFN 层中展现出比 ReLU/GeLU 更强的性能；<strong>旋转位置编码（RoPE）</strong> 解决了长序列建模的难题。这些组件共同构成了一个鲁棒、高性能的 Transformer 骨架。</p>
<h4 id="172-1b-10b-w7">17.2 1B 与 10B 架构参数表 [里程碑 W7]</h4>
<p>我们采取“两步走”策略：1B Dense 模型作为“侦察兵”，用于快速趟平数据、训练、评测全链路的各种坑；10B MoE 模型则是我们的“主战坦克”，承载着冲击业界顶尖性能的使命。</p>
<p>| 参数 (Parameter) | 1B (Dense) 参考值 | 10B (MoE) 参考值 | 设计 rationale / 权衡考量 |</p>
<table>
<thead>
<tr>
<th style="text-align: left;">参数 (Parameter)</th>
<th style="text-align: left;">1B (Dense) 参考值</th>
<th style="text-align: left;">10B (MoE) 参考值</th>
<th style="text-align: left;">设计 rationale / 权衡考量</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><strong>总参数量</strong></td>
<td style="text-align: left;">~1.3B</td>
<td style="text-align: left;">~12B (激活 ~2B)</td>
<td style="text-align: left;">MoE 以存储换计算。总参数量巨大，但单样本前向传播仅激活一小部分（约 2B），实现“大容量、低成本”推理。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>模型类型</strong></td>
<td style="text-align: left;">Dense</td>
<td style="text-align: left;">Mixture-of-Experts (MoE)</td>
<td style="text-align: left;">1B 验证全流程，成本可控。10B 追求知识广度与深度，MoE 是在给定算力下最大化模型容量的关键技术。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>层数 (Layers, <code>n_layer</code>)</strong></td>
<td style="text-align: left;">24</td>
<td style="text-align: left;">32</td>
<td style="text-align: left;">更深的模型倾向于学习到更抽象的层次化特征，这对于理解复杂的 VLA 场景至关重要。10B 模型有能力支撑更深的结构。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>隐藏层维度 (<code>d_model</code>)</strong></td>
<td style="text-align: left;">2048</td>
<td style="text-align: left;">4096</td>
<td style="text-align: left;">更宽的隐藏层为多模态特征的融合提供了更丰富的“信息总线”，减少信息瓶颈。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>注意力头数 (<code>n_head</code>)</strong></td>
<td style="text-align: left;">16</td>
<td style="text-align: left;">32</td>
<td style="text-align: left;">与 <code>d_model</code> 等比例增长，确保每个头的维度（<code>d_head</code> = 128）不变。这有助于模型从不同子空间捕获特征。可考虑 GQA/MQA 优化推理。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>FFN 中间层比例</strong></td>
<td style="text-align: left;">8/3 (e.g., <code>d_ff</code>=5461)</td>
<td style="text-align: left;">N/A (见 MoE)</td>
<td style="text-align: left;">SwiGLU FFN 的中间层维度通常是 <code>(2/3) * 4 * d_model</code>。这是一个被践证明的经验值。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>MoE 专家数 (<code>num_experts</code>)</strong></td>
<td style="text-align: left;">N/A</td>
<td style="text-align: left;">16</td>
<td style="text-align: left;">16 是一个常见的权衡点。专家数太少，MoE 优势不明显；太多则导致路由难度和通信开销剧增。在 256 H100 集群上，可方便地按节点或 Pod 进行专家并行。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>MoE 激活专家数 (<code>top_k</code>)</strong></td>
<td style="text-align: left;">N/A</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">Top-2 路由相比 Top-1 能显著提升性能和训练稳定性，而计算量仅翻倍。Top-4 收益递减，成本更高。部署时可切换为 Top-1 以加速。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>上下文长度</strong></td>
<td style="text-align: left;">32,768 tokens</td>
<td style="text-align: left;">65,536 tokens</td>
<td style="text-align: left;">这是产品能力的核心指标。32k 已能处理多数长文档和短视频，而 64k 则为处理多分钟的长视频、复杂的驾驶场景和维持长期记忆提供了可能。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>位置编码</strong></td>
<td style="text-align: left;">RoPE (Rotary)</td>
<td style="text-align: left;">RoPE (Rotary)</td>
<td style="text-align: left;">对于数万 token 的长上下文，RoPE 的优秀外推性和稳定性是其成为不二之选的核心原因。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>归一化</strong></td>
<td style="text-align: left;">RMSNorm (Pre-Norm)</td>
<td style="text-align: left;">RMSNorm (Pre-Norm)</td>
<td style="text-align: left;">Pre-Norm 结构有助于梯度稳定，是训练深度 Transformer 的关键。RMSNorm 相比 LayerNorm 计算量更小。</td>
</tr>
<tr>
<td style="text-align: left;"><strong>激活函数</strong></td>
<td style="text-align: left;">SwiGLU</td>
<td style="text-align: left;">SwiGLU</td>
<td style="text-align: left;">Gated Linear Unit (GLU) 的一种变体，通过门控机制动态调整信息流，被证明在多种任务上优于传统激活函数。</td>
</tr>
</tbody>
</table>
<h4 id="173-early-fusion">17.3 多模态早期融合 (Early Fusion) 与投影器</h4>
<p>“早期融合”意味着所有模态在进入 Transformer 主体网络的第一层之前，就已经被转换到同一个高维语义空间中。这使得模型能够从最底层就开始进行跨模态信息的深度交互与对齐。</p>
<div class="codehilite"><pre><span></span><code><span class="c">      </span><span class="nb">+-----------------+</span><span class="c">      </span><span class="nb">+-----------------+</span><span class="c">      </span><span class="nb">+---------------------+</span>
<span class="c">Text  |  Text Tokenizer | </span><span class="nb">---</span><span class="nv">&gt;</span><span class="c"> |   Embedding     | </span><span class="nb">--+</span><span class="c">  |                     |</span>
<span class="c">      </span><span class="nb">+-----------------+</span><span class="c">      </span><span class="nb">+-----------------+</span><span class="c">   |  |                     |</span>
<span class="c">                                                     v  |                     |</span>
<span class="c">      </span><span class="nb">+-----------------+</span><span class="c">      </span><span class="nb">+-----------------+</span><span class="c">      |                     |      </span><span class="nb">+-----------------+</span>
<span class="c">Image/|  Patch Encoder  | </span><span class="nb">---</span><span class="nv">&gt;</span><span class="c"> | Vision Projector| </span><span class="nb">---</span><span class="nv">&gt;</span><span class="c"> |   Transformer       |      |  LM Head /      |</span>
<span class="c">Video | (e</span><span class="nt">.</span><span class="c">g</span><span class="nt">.,</span><span class="c"> ViT</span><span class="nb">-</span><span class="c">L)   |      | (Perceiver</span><span class="nb">-</span><span class="c">like)| </span><span class="nb">--+</span><span class="c">  |   Backbone          | </span><span class="nb">---</span><span class="nv">&gt;</span><span class="c"> |  Action Head    |</span>
<span class="c">      </span><span class="nb">+-----------------+</span><span class="c">      </span><span class="nb">+-----------------+</span><span class="c">   |  | (1B Dense / 10B MoE)|      </span><span class="nb">+-----------------+</span>
<span class="c">                                                     v  |                     |</span>
<span class="c">      </span><span class="nb">+-----------------+</span><span class="c">      </span><span class="nb">+-----------------+</span><span class="c">      |                     |</span>
<span class="c">Audio |  Audio Codec    | </span><span class="nb">---</span><span class="nv">&gt;</span><span class="c"> | Audio Projector | </span><span class="nb">--+</span><span class="c">  |                     |</span>
<span class="c">      |    Tokens       |      |  (Embedding)    |      |                     |</span>
<span class="c">      </span><span class="nb">+-----------------+</span><span class="c">      </span><span class="nb">+-----------------+</span><span class="c">      </span><span class="nb">+---------------------+</span>
</code></pre></div>

<ul>
<li>
<p><strong>视觉投影器 (Vision Projector) - Perceiver 式压缩是关键</strong>
    一段 6-cam @ 480p @ 12Hz 的 10 秒视频会产生巨量的视觉 token，直接输入 Transformer 会导致序列过长，计算爆炸。为此，我们采用 <strong>Perceiver 式的重采样/压缩</strong> 机制：</p>
<ol>
<li><strong>分块与编码</strong>：视频帧被切分为重叠的 patches，每个 patch 经过一个小型视觉编码器（如 ViT-L 的一部分）得到一个 embedding。此时，我们会得到一个极其庞大的视觉 token 序列。</li>
<li><strong>时空嵌入</strong>：为每个视觉 token 添加<strong>可学习的嵌入向量</strong>，以编码其来源信息：相机 ID (1-6)、时间戳、在图像中的 2D 位置。这是模型理解多摄环视时空关系的基础。</li>
<li><strong>交叉注意力压缩</strong>：引入一小组（例如 256 个）可学习的<strong>“潜查询” (latent query) 向量</strong>。这些 query 通过交叉注意力机制去“审视”和“提炼”海量的原始视觉 token，将其中最重要的信息压缩并汇总到这 256 个 query 的 embedding 中。</li>
<li><strong>输出</strong>：最终，无论原始视频多长，视觉投影器都稳定输出一个长度为 256 的 token 序列，送入主干网络。这极大地降低了计算复杂度。</li>
</ol>
</li>
<li>
<p><strong>音频投影器 (Audio Projector)</strong>
    由于我们采用了神经音频编解码器，音频已被转化为离散 token。这里的投影器相对简单，主要是一个标准的 Embedding 层，将离散的音频 token ID 映射为 <code>d_model</code> 维的向量。IPA token 序列可以作为并行的另一路输入，通过另一个 Embedding 层后与音频 token embedding 相加或拼接，为模型提供音素级别的先验知识。</p>
</li>
<li>
<p><strong>3D 投影器 (3D Projector)</strong>
    遵循第 9 章的优先级：</p>
<ol>
<li><strong>程序化脚本/X3D</strong>：这些本身就是文本，直接通过扩展后的文本 Tokenizer 处理。</li>
<li><strong>.obj 等网格格式</strong>：将其语法（如 <code>v</code>, <code>vn</code>, <code>f</code>）和数值离散化后，也看作一个特殊的“语言”，通过 Embedding 层进行投影。</li>
</ol>
</li>
<li>
<p><strong>最终组装</strong>
    所有模た的 embedding 序列，连同特殊的边界 token（如 <code>&lt;|vision_start|&gt;</code>, <code>&lt;|audio_end|&gt;</code>），在序列维度上被拼接 (<code>torch.cat</code>) 起来，形成一个完整的、超长的多模态输入序列，最后送入 Transformer 主干网络。</p>
</li>
</ul>
<h4 id="174-moe-10b">17.4 详解“先进 MoE”架构 (10B)</h4>
<p>准的 MoE 已经强大，但“先进”体现在对路由策略、负载均衡和通信优化的精细打磨上，这些细节决定了训练的成败。</p>
<div class="codehilite"><pre><span></span><code><span class="w">          </span><span class="k">Input</span><span class="w"> </span><span class="n">Token</span><span class="w"> </span><span class="n">Embedding</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="w">                      </span><span class="o">|</span>
<span class="w">                      </span><span class="n">v</span>
<span class="w">      </span><span class="o">+----------------------------------+</span>
<span class="w">      </span><span class="o">|</span><span class="w"> </span><span class="n">Gating</span><span class="w"> </span><span class="n">Network</span><span class="w"> </span><span class="p">(</span><span class="n">Router</span><span class="p">)</span><span class="w">          </span><span class="o">|</span>
<span class="w">      </span><span class="o">|</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Softmax</span><span class="p">(</span><span class="n">Linear</span><span class="p">(</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span><span class="o">|</span><span class="w"> </span><span class="o">--</span>
<span class="w">      </span><span class="o">+----------------------------------+</span><span class="w">   </span><span class="o">|--&gt;</span><span class="w"> </span><span class="n">计算路由权重</span><span class="w"> </span><span class="n">g_1</span><span class="p">,</span><span class="w"> </span><span class="n">g_2</span><span class="p">,</span><span class="w"> </span><span class="p">...</span>

<span class="w">      </span><span class="o">+----------------------------------+</span><span class="w">   </span><span class="o">|--&gt;</span><span class="w"> </span><span class="n">计算路由权重</span><span class="w"> </span><span class="n">g_1</span><span class="p">,</span><span class="w"> </span><span class="n">g_2</span><span class="p">,</span><span class="w"> </span><span class="p">...</span>
<span class="w">        </span><span class="o">|</span><span class="w">                </span><span class="o">|</span><span class="w">                   </span><span class="o">|</span>
<span class="w">        </span><span class="n">v</span><span class="w">                </span><span class="n">v</span><span class="w">                   </span><span class="o">|</span>
<span class="w">  </span><span class="o">[</span><span class="n">g_1</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">g_2</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="p">...</span><span class="w"> </span><span class="o">[</span><span class="n">g_k</span><span class="o">]</span><span class="w"> </span><span class="p">(</span><span class="k">Top</span><span class="o">-</span><span class="n">k</span><span class="w"> </span><span class="n">weights</span><span class="p">)</span><span class="w">    </span><span class="o">|</span>
<span class="w">        </span><span class="o">|</span><span class="w">                </span><span class="o">|</span><span class="w">                   </span><span class="o">|</span>

<span class="o">+-----------+</span><span class="w">      </span><span class="o">+-----------+</span><span class="w">         </span><span class="o">+-----------+</span>
<span class="o">|</span><span class="w"> </span><span class="n">Expert</span><span class="w"> </span><span class="mi">1</span><span class="w">  </span><span class="o">|</span><span class="w">      </span><span class="o">|</span><span class="w"> </span><span class="n">Expert</span><span class="w"> </span><span class="mi">2</span><span class="w">  </span><span class="o">|</span><span class="w">   </span><span class="p">...</span><span class="w">   </span><span class="o">|</span><span class="w"> </span><span class="n">Expert</span><span class="w"> </span><span class="mi">16</span><span class="w"> </span><span class="o">|</span>
<span class="o">|</span><span class="w">  </span><span class="n">FFN</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w">   </span><span class="o">|</span><span class="w">      </span><span class="o">|</span><span class="w">  </span><span class="n">FFN</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w">   </span><span class="o">|</span><span class="w">         </span><span class="o">|</span><span class="w">  </span><span class="n">FFN</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w">   </span><span class="o">|</span>
<span class="o">+-----------+</span><span class="w">      </span><span class="o">+-----------+</span><span class="w">         </span><span class="o">+-----------+</span>
<span class="w">        </span><span class="o">|</span><span class="w">                </span><span class="o">|</span>
<span class="w">        </span><span class="n">v</span><span class="w">                </span><span class="n">v</span>
<span class="w">        </span><span class="err">\</span><span class="w">                </span><span class="o">/</span>
<span class="w">         </span><span class="err">\</span><span class="w">              </span><span class="o">/</span>
<span class="w">      </span><span class="k">Output</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sum_</span><span class="err">{</span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">TopK</span><span class="err">}</span><span class="p">(</span><span class="n">g_i</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">Expert_i</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</code></pre></div>

<ul>
<li><strong>带噪声的 Top-k 路由 (Noisy Top-k Gating)</strong>: 为提升探索性，防止路由策略过早固化，可以在路由器的 logits 上加入少量高斯噪声。$G(x) = \text{Softmax}(\text{Linear}(x) + \epsilon)$, where $\epsilon \sim \mathcal{N}(0, \sigma^2)$。这在训练早期尤其有效。</li>
<li><strong>专家容量 (Expert Capacity)</strong>: 在硬件实现中，每个专家的计算缓冲区大小是固定的。如果某个专家被分配的 token 数超过其容量，多余的 token 就会被<strong>丢弃 (dropped)</strong>。这是一个重要的 trade-off。<ul>
<li><strong>容量因子 (Capacity Factor, C)</strong>: 通常设置为 <code>C = (总 token 数 / 专家数) * 1.25</code>。因子 <code>1.25</code> 意味着我们为每个专家预留了 25% 的冗余容量，以应对路由不均。</li>
<li><strong>监控丢弃率</strong>是 MoE 训练的关键指标。持续的高丢弃率意味着负载均衡出了问题，模型容量被浪费。</li>
</ul>
</li>
<li>
<p><strong>精细的负载均衡损失 ($\mathcal{L}_{\text{aux}}$)</strong>: 我们采用结合了“利用”和“重要性”的辅助损失。</p>
<ul>
<li><strong>利用率</strong>: 鼓励每个专家处理大致相同数量的 token。</li>
<li><strong>重要性</strong>: 鼓励路由权重 $g_i$ 在所有 token 上的总和也趋于均衡。
$\mathcal{L}_{\text{aux}} = \alpha \cdot (\mathbf{f} \cdot \mathbf{P})$, 其中 $\mathbf{f}$ 是各专家接收 token 的比例向量，$\mathbf{P}$ 是各专家路由权重的总和向量。$\alpha$ 是需要仔细调整的超参数。</li>
</ul>
</li>
<li>
<p><strong>专家并行与通信</strong>：在 Megatron 框架下，专家并行 (EP) 与张量并行 (TP) 和流水线并行 (PP) 正交。通常，我们会将 TP 限制在单个节点内（利用 NVLink），而 EP 和 DP (数据并行) 会跨节点（利用 InfiniBand）。MoE 的 FFN 计算中，会触发两次 <code>All-to-All</code> 通信：一次将 token 从它们的原始 GPU 发送到其被路由到的专家所在 GPU，一次将计算结果发回。这是 MoE 训练的主要通信瓶颈。</p>
</li>
</ul>
<h4 id="175-vla">17.5 VLA 核心：连接“思想”与“行动”</h4>
<p>模型的行动能力源于其生成特定动作 token 的能力。</p>
<ul>
<li><strong>动作离散化与词表</strong>：我们将自动驾驶和具身智能的连续动作空间（如转向、油门、机械臂关节角度）进行<strong>量化 (Quantization)</strong>，映射到词表中的离散 token。<ul>
<li><strong>示例</strong>: 方向盘转角 <code>[-90°, 90°]</code> 可以被量化为 256 个 bin，每个 bin 对应一个 token，如 <code>&lt;action_steer_bin_0&gt;</code> 到 <code>&lt;action_steer_bin_255&gt;</code>。</li>
<li><strong>权衡</strong>: 粒度越细，控制越精确，但词表变大，模型学习难度增加；粒度越粗，学习简单，但控制精度下降。我们需要根据任务需求找到最佳平衡点。</li>
</ul>
</li>
<li><strong>分层动作 (Hierarchical Actions)</strong>：为了让模型具备规划能力，我们设计了分层动作空间。模型首先生成一个高层级的意图 token (e.g., <code>&lt;maneuver_lane_change_left&gt;</code>)，然后在此基础上生成一系列低层级的微操 token（转向、加速等）。这使得模型的行为更具可解释性。</li>
<li><strong>动作头 (Action Head)</strong>：虽然理论上可以与语言模型头 (LM Head) 共享，但实践中，为动作 token 设立一个独立的、轻量级的线性预测头通常更稳定。这意味着模型的最终输出层有两个“出口”：一个预测通用词表，一个预测动作词表。训练时，根据下一个真实 token 的类型（是语言还是动作），选择对应的头计算损失。
    $ \mathcal{L}_{\text{total}} = \mathcal{L}_{\text{LM}} + \beta \cdot \mathcal{L}_{\text{Action}} $
    其中 $\beta$ 是平衡语言和动作学习的权重。</li>
</ul>
<h3 id="3">3. 本章小结</h3>
<p>本章为我们的 VLA 大模型构建了详尽而坚实的架构基础。我们不仅确定了宏观路线，也深入到了每一个关键组件的设计细节中。</p>
<ul>
<li><strong>核心架构</strong>: 选定以 <strong>Qwen 式自回归 Transformer</strong> 为统一骨架，利用其强大的生成能力驱动多模态理解与行动。</li>
<li><strong>双规并行</strong>: 冻结了 <strong>1B Dense</strong>（用于快速迭代）和 <strong>10B 先进 MoE</strong>（用于性能突破）两套模型的详细参数配置，明确了各自的设计哲学。</li>
<li><strong>多模态融合</strong>: 设计了<strong>早期融合</strong>方案，特别是引入了 <strong>Perceiver 式压缩</strong>来高效处理海量的多摄视频输入，并通过时空嵌入保留关键的几何与时序信息。</li>
<li><strong>MoE 机制</strong>: 深入剖析了“先进 MoE”的内涵，包括带噪声路由、专家容量、精细负载均衡损失等核心机制，并指出了其在分布式训练中的通信模式。</li>
<li><strong>VLA 实现</strong>: 通过<strong>动作离散化</strong>、<strong>分层动作设计</strong>和独立的<strong>动作头</strong>，为模型赋予了将“思想”转化为具体“行动”的能力，打通了感知-语言-行动的闭环。</li>
</ul>
<h3 id="4-gotchas">4. 常见陷阱与错误 (Gotchas)</h3>
<ol>
<li>
<p><strong>MoE 路由坍塌 (Router Collapse)</strong>:</p>
<ul>
<li><strong>现象</strong>: 训练中，专家负载极不均衡，部分专家“门庭若市”，部分“门可罗雀”，模型有效容量锐减，损失停滞。</li>
<li><strong>调试</strong>: 监控专家 token 分布直方图和 token 丢弃率。检查路由器的梯度，确保量级正常。</li>
<li><strong>预防措施</strong>: 使用<strong>路由器 Z-loss</strong> 来惩罚过大的 router logits；从一个较小的负载均衡系数 <code>α</code> 开始，然后随训练逐步增大学习率。在混合精度训练中，确保路由器的计算在 FP32 下进行以保证数值稳定性。</li>
</ul>
</li>
<li>
<p><strong>多模态特征尺度不一 (Mismatched Modality Scales)</strong>:</p>
<ul>
<li><strong>现象</strong>: 训练初期损失曲线剧烈震荡或直接 NaN。通常是某一模态（如视觉）的 embedding 范数远大于其他模态，导致梯度爆炸。</li>
<li><strong>调试</strong>: 在送入 Transformer 主干前，打印并监控每个模态投影器输出的 embedding 的 L2 范数。</li>
<li><strong>预防措施</strong>: 对每个模态的输出序列<strong>独立进行一次 RMSNorm</strong>。这是在多模态融合前最简单有效的“尺度对齐”手段。</li>
</ul>
</li>
<li>
<p><strong>视觉压缩信息瓶颈 (Vision Compression Bottleneck)</strong>:</p>
<ul>
<li><strong>现象</strong>: 模型在需要精细视觉细节的任务上（如识别小物体、读取仪表盘）表现不佳，尽管整场景理解尚可。</li>
<li><strong>调试</strong>: 可能是 Perceiver 的潜查询数量太少（如 64 个），导致压缩过于激进，丢失了高频细节。</li>
<li><strong>预防措施</strong>: 将潜查询数量作为一个重要的超参数进行实验。可以从 256 个开始。另外，可以设计混合方案：保留一小部分原始的高分辨率 patch token，与压缩后的潜查询 token 一起送入模型。</li>
</ul>
</li>
<li>
<p><strong>MoE 通信瓶颈 (MoE Communication Bottleneck)</strong>:</p>
<ul>
<li><strong>现象</strong>: 实际训练吞吐（TFLOPs/GPU/s）远低于理论峰值，<code>nvidia-smi</code> 显示 GPU 利用率不高，但网络带宽占用很高。</li>
<li><strong>调试</strong>: 使用 <code>nsight-sys</code> 等工具剖析训练 step，确认时间是否主要消耗在 <code>All-to-All</code> 通信原语上。</li>
<li><strong>预防措施</strong>: 与 Infra 团队紧密协作，优化集群拓扑。<strong>将专家尽可能地分组在通信最快的单元内</strong>（例如，一个 8-H100 NVLink 节点内的 8 个专家），以最大化利用高带宽的 NVLink，减少对较慢的跨节点 InfiniBand 的依赖。</li>
</ul>
</li>
<li>
<p><strong>动作抖动与不稳定性 (Action Jitter &amp; Instability)</strong>:</p>
<ul>
<li><strong>现象</strong>: 在模拟器中，模型生成的动作序列在相邻的几个 bin 之间高频切换，导致车辆或机械臂产生不平滑、抖动的行为。</li>
<li><strong>调试</strong>: 检查动作 token 序列的熵。高熵可能意味着模型对选择哪个动作 bin 没有信心。</li>
<li><strong>预防措施</strong>: 引入<strong>动作平滑正则化损失</strong>，惩罚连续时间步之间动作的大幅变化。另外，在 SFT 阶段，使用高质量的人类驾驶/操作数据进行微调，让模型学习平滑的控制策略。</li>
</ul>
</li>
</ol>
            </article>
            
            <nav class="page-nav"><a href="chapter16.html" class="nav-link prev">← [chapter16.md] 生成‑理解一体架构沿革</a><a href="chapter18.html" class="nav-link next">[chapter19.md] 训练配方：从 1B 到 10B 的生产级方案 →</a></nav>
        </main>
    </div>
</body>
</html>
<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="./">
    <title>第 12 章：合成数据 I：教科书式文本/指令（Phi-3 风格）</title>
    <link rel="stylesheet" href="assets/style.css">
    <link rel="stylesheet" href="assets/highlight.css">
    <script src="assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors', 'ams']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors', '[tex]/ams']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>目录</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <div class="sidebar-search">
                <input type="text" id="sidebar-search-input" placeholder="搜索..." autocomplete="off">
            </div>
            <div id="tree-container">
                <nav class="tree-nav" role="tree">
                    <div class="tree-item " >
                        <a href="index.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">面向 Vision‑Language‑Action（VLA）、自动驾驶/具身与语音交互的多模态大模型预训练教程（公开版）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter1.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">[chapter1.md] 前言、范围与读者指南</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter2.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 2 章：全局时间线与里程碑（W0–W26）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter3.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第三章：需求拆解与系统能力画像（VLA / AD / 语音）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter4.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第四章：数据总体策略与 30T token 配额（多语多模）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter5.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第五章 数据采集 I：网页文本与代码（合规）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter6.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 6 章：数据采集 II：音频/语音（播客、公开课、语音数据集）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter7.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 7 章 数据采集 III：视频（长/短视频、驾驶/具身）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter8.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">[chapter8.md] 数据采集 IV：图像</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter9.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 9 章 数据采集 V：3D（程序化优先）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter10.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十章：数据治理与质量度量（跨模态）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter11.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 11 章 过滤与去脏：fastText 与小模型策略库</span>
                        </a>
                    </div>
                
                    <div class="tree-item active" >
                        <a href="chapter12.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 12 章：合成数据 I：教科书式文本/指令（Phi-3 风格）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter13.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第十三章 合成数据 II：音频与语音</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter14.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 14 章 合成数据 III：视频与 VLA 自博弈（Agentic RL Self‑Play）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter15.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Tokenizer 设计：文本/音频/视频/图像/3D</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter16.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">[chapter16.md] 生成‑理解一体架构沿革</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter17.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">[chapter17.md] 模型架构：Qwen‑式自回归 Transformer（Dense / 先进 MoE，早期融合）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter18.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">[chapter19.md] 训练配方：从 1B 到 10B 的生产级方案</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter19.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">[chapter19.md] 训练配方：从 1B 到 10B 的生产级方案</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter20.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 20 章 蒸馏与教师模型：Gemma‑式 Logits 蒸馏及多模态知识迁移</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter21.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">[chapter21.md] 对齐与中期训练（Instruction/Mid-training/偏好）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter22.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 22 章：评测与基准（多模/多语/VLA/驾驶/语音）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter23.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">[chapter23.md] 成本、运维与 MLOps</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter24.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 24 章：交付与复现</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter25.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">第 25 章：安全、法律与合规</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter26.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">[chapter26.md] 项目管理与人员阵型：大型AI工程的“交响乐指挥法”</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter27.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">`[chapter27.md]` 常见陷阱与故障排查</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter28.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">附录 A：配置与脚本模板（可复制）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="appendixA.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">附录 A：配置与脚本模板（可复制）</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="CLAUDE.html" class="tree-link">
                            <span class="tree-icon">📄</span>
                            <span class="tree-title">Untitled</span>
                        </a>
                    </div>
                </nav>
            </div>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="12-iphi-3">第 12 章：合成数据 I：教科书式文本/指令（Phi-3 风格）</h1>
<h2 id="_1">开篇段落</h2>
<p>尽管我们在前几章中投入了巨大努力从公开渠道采集了海量数据，但必须清醒地认识到网络数据的“诅咒”：知识密度低、信噪比差、逻辑链条残缺，且充斥着非结构化、非正式的表达。完全依赖这类数据进行预训练，模型更倾向于学习表面统计规律而非深层因果和逻辑推理。为突破这一瓶颈，本章将详细阐述一种战略性的数据增强方法——大规模、高质量地合成“教科书”风格的数据。该策略受到 Phi-3 等前沿工作的启发，其核心思想是，<strong>用小而精的高质量数据，可以实现甚至超越更大规模低质量数据的训练效果</strong>，尤其是在推理、数学、编程和复杂指令遵循等核心认知能力上。我们将此阶段定义为<strong>“强中期训练（Strong Mid-training）”</strong>的关键组成部分。本章将从顶层设计、数据生产线构建、思维过程注入，到成本控制与数据纯净性保障，提供一套完整的工业级实施方案。</p>
<p><strong>学习目标</strong>:</p>
<ol>
<li>深刻理解合成“教科书”数据在弥补网络数据短板、提升模型认知能力上的战略价值。</li>
<li>掌握从零开始设计与管理覆盖多领域知识的<strong>知识网格（Knowledge Grid）</strong>与<strong>课程蓝图（Curriculum Blueprint）</strong>。</li>
<li>学习如何构建一个由<strong>模板驱动生成</strong>与<strong>多层自动验证</strong>组成的、可扩展、可迭代的高质量数据生产线。</li>
<li>精通如何通过<strong>难度爬坡（Difficulty Curriculum）</strong>、<strong>思维链（Chain-of-Thought, CoT）</strong>和<strong>工具使用（Tool-use）</strong>信号，教会模型“如何思考”而非仅仅“知道什么”。</li>
<li>掌握工业级的<strong>数据去污议（Data Decontamination Protocol）</strong>，以杜绝评测集泄漏，确保模型评估的科学性和公正性。</li>
<li>理解合成数据生成的<strong>经济学考量</strong>与规模化部署的工程挑战。</li>
</ol>
<hr />
<h2 id="121-w6">12.1 顶层设计：从知识网格到课程蓝图 [里程碑 W6]</h2>
<p>高质量合成数据的根基在于系统化的顶层规划，而非随机生成。我们的第一步是像编纂一部现代数字百科全书一样，构建一个结构化的知识体系。</p>
<h4 id="1211-knowledge-grid">12.1.1 知识网格（Knowledge Grid）的构建</h4>
<p>知识网格是一个有向无环图（DAG），它将人类知识结构化，以指导我们的数据生成。</p>
<ul>
<li><strong>节点 (Nodes)</strong>: 代表一个原子化的知识概念或技能。例如：<code>Python:ListComprehension</code>、<code>Physics:NewtonSecondLaw</code>、<code>Logic:ModusPonens</code>、<code>Driving:LaneKeepingAssist</code>。每个节点都应有元数据，如领域、难度等级、关键词等。</li>
<li><strong>边 (Edges)</strong>: 代表知识间的依赖关系。例如，<code>Calculus:Derivatives</code> 节点依赖于 <code>Algebra:Functions</code> 和 <code>Algebra:Limits</code> 节点。这为后续的难度爬坡（Curriculum Learning）提供了基础。</li>
</ul>
<p><strong>构建流程</strong>:</p>
<ol>
<li><strong>领域专家输入</strong>: 邀请计算机科学、数学、物理、法律、伦理学以及自动驾驶领域的专家，共同定义核心知识领域。</li>
<li><strong>参考现有体系</strong>: 大量借鉴成熟的知识体系，如 MIT OpenCourseWare 的课程大纲、ACM Computing Curricula、可汗学院的技能树、国家中小学课程标准等，将其结构化并导入我们的网格。</li>
<li><strong>工具化管理</strong>: 使用图数据库（如 Neo4j）或简单的版本化文件（如 YAML/JSON 在 Git 中管理）来存储和维护知识网格。这保证了它的可追溯性、可协作性和可扩展性。</li>
</ol>
<div class="codehilite"><pre><span></span><code><span class="w">          </span><span class="p">[</span><span class="n">CS</span><span class="w"> </span><span class="n">Foundations</span><span class="p">]</span><span class="err">───────────────────┐</span>
<span class="w">         </span><span class="o">/</span><span class="w">      </span><span class="o">|</span><span class="w">       </span><span class="err">\</span><span class="w">                    </span><span class="o">|</span>
<span class="w">    </span><span class="p">[</span><span class="n">Algorithms</span><span class="p">]</span><span class="w">  </span><span class="p">[</span><span class="n">Data</span><span class="w"> </span><span class="n">Structures</span><span class="p">]</span><span class="w">  </span><span class="p">[</span><span class="n">Programming</span><span class="w"> </span><span class="n">Paradigms</span><span class="p">]</span>
<span class="w">       </span><span class="o">|</span><span class="w">         </span><span class="o">/</span><span class="w">      </span><span class="err">\</span><span class="w">              </span><span class="o">/</span><span class="w">           </span>\
<span class="w"> </span><span class="p">[</span><span class="n">Sorting</span><span class="p">]</span><span class="w">  </span><span class="p">[</span><span class="n">Arrays</span><span class="p">]</span><span class="w">  </span><span class="p">[</span><span class="n">Linked</span><span class="w"> </span><span class="n">Lists</span><span class="p">]</span><span class="w">  </span><span class="p">[</span><span class="n">OOP</span><span class="p">]</span><span class="w">      </span><span class="p">[</span><span class="n">Functional</span><span class="p">]</span>
<span class="w">    </span><span class="o">|</span><span class="w">          </span><span class="err">\</span><span class="w">      </span><span class="o">/</span><span class="w">                 </span><span class="o">|</span>
<span class="w"> </span><span class="p">[</span><span class="n">QuickSort</span><span class="p">]</span><span class="w">    </span><span class="p">[</span><span class="n">Hash</span><span class="w"> </span><span class="n">Tables</span><span class="p">]</span><span class="w">        </span><span class="p">[</span><span class="n">Polymorphism</span><span class="p">]</span>
<span class="w">       </span><span class="err">\</span><span class="w">         </span><span class="o">/</span>
<span class="w">        </span><span class="err">\───────</span><span class="o">/</span>
<span class="w">   </span><span class="p">[</span><span class="n">Complex</span><span class="w"> </span><span class="n">Data</span><span class="w"> </span><span class="n">Structures</span><span class="p">]</span>
</code></pre></div>

<p><em>图 12.1：计算机科学领域知识网格的局部示意图</em></p>
<h4 id="1212-curriculum-blueprint">12.1.2 课程-章-节蓝图（Curriculum Blueprint）</h4>
<p>知识网格是抽象的，我们需要将其转化为具体的、可执行的生成任务列表，即课程蓝图。</p>
<ul>
<li><strong>课程 (Course)</strong>: 对应一个宏观领域，例如 <code>CS101: Introduction to Python Programming</code>。</li>
<li><strong>章 (Chapter)</strong>: 对应一个核心主题，例如 <code>Chapter 5: Data Structures</code>。</li>
<li><strong>节 (Section)</strong>: 对应一个或多个紧密相关的知识节点，例如 <code>Section 5.2: Dictionaries and Sets</code>。</li>
<li><strong>学习目标 (Learning Objectives)</strong>: 每一节都应有明确的学习目标，这些目标将直接转化为生成模板中的具体指令。</li>
</ul>
<blockquote>
<p><strong>Rule-of-thumb</strong>:
知识网格的构建应平衡<strong>广度</strong>与<strong>深度</strong>。在项目初期，快速构建一个覆盖所有目标领域的“骨架”网格，然后随着项目的进行，逐步在关键领域（如代码、推理）填充“血肉”，增加深度和细节。这个网格是一个需要持续迭代和维护的活资产。</p>
</blockquote>
<p><strong>[里程碑 W6]</strong>：完成覆盖编程、数学、逻辑推理、世界知识、安全伦理、自动驾驶规则等核心领域的 V1.0 知识网格和课程蓝图。这份蓝图将成为接下来数周合成数据生产的“总指挥图”。</p>
<hr />
<h2 id="122">12.2 生成与验证：构建高质量的数据生产线</h2>
<p>有了蓝图，我们现在需要搭建一条高效、可靠的数据“生产线”，采用“生成-验证（Generator-Validator）”的闭环模式。</p>
<h4 id="1221-generation-templates">12.2.1 规则化生成模板（Generation Templates）</h4>
<p>结构化的 Prompt 模板是保证输出质量与格式统一性的关键。我们为不同类型的内容（概念解释、代码示例、问答、对话等）设计不同的模板。</p>
<p><strong>示例模板：代码生成与解释</strong></p>
<div class="codehilite"><pre><span></span><code><span class="nn">---</span>
<span class="c1"># metadata</span>
<span class="nt">knowledge_node_id</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;Python:Decorators&quot;</span>
<span class="nt">difficulty</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;中级&quot;</span>
<span class="nt">template_version</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.2</span>

<span class="c1"># instructions for generator model</span>
<span class="nt">prompt</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|</span>
<span class="w">  </span><span class="no">你是一位资深的Python技术作家，正在为一本高级教程撰写关于“装饰器”的一节。</span>
<span class="w">  </span><span class="no">请遵循以下结构，生成内容：</span>

<span class="w">  </span><span class="no">1.  **定义 (Definition)**: 用一个精准的比喻（例如“给函数穿上外衣”）和一个技术的定义来解释什么是装饰器。</span>
<span class="w">  </span><span class="no">2.  **核心思想 (Core Idea)**: 解释装饰器如何利用函数是“一等公民”的特性。</span>
<span class="w">  </span><span class="no">3.  **代码示例 (Code Example)**:</span>
<span class="w">      </span><span class="no">- 编写一个简单的日志记录装饰器 `@log_execution`。</span>
<span class="w">      </span><span class="no">- 将它应用于一个计算斐波那契数列的函数。</span>
<span class="w">      </span><span class="no">- 展示调用被装饰函数后的输出。</span>
<span class="w">      </span><span class="no">- 保证代码简洁、PEP8风格、可直接运行，并有高质量的注释。</span>
<span class="w">  </span><span class="no">4.  **语法糖 (Syntactic Sugar)**: 解释 `@` 符号是如何等价于 `my_func = my_decorator(my_func)` 的。</span>
<span class="w">  </span><span class="no">5.  **练习题 (Exercise)**: 设计一练习题，要求读者编写一个能给函数执行计时的装饰器。</span>
<span class="nn">---</span>
</code></pre></div>

<h4 id="1222-multi-stage-validators">12.2.2 多层验证器（Multi-Stage Validators）</h4>
<p>生成的内容必须通过一系列严格的自动化检查，不合格品将被退回或丢弃。</p>
<ol>
<li>
<p><strong>结构与语法验证器 (L1)</strong>:</p>
<ul>
<li><strong>格式检查</strong>: 验证输出是否为合法的 Markdown、JSON 或其他预定格式。</li>
<li><strong>代码检查</strong>: 对生成的代码片段，调用静态分析工具（linter，如 <code>pylint</code>）检查语法错误和代码风格。更进一步，可以尝试<strong>自动生成单元测试</strong>并运行，验证代码的基本功能正确性。</li>
</ul>
</li>
<li>
<p><strong>语义与事实验证器 (L2)</strong>:</p>
<ul>
<li><strong>一致性检查</strong>: 生成的练习题答案是否能正确解答对应的问题？代码输出是否与描述相符？</li>
<li><strong>事实核查</strong>: 利用一个更强大的“裁判”模型（Judge LLM）或知识库API，对生成内容中的关键事实进行交叉验证。例如，提问：“以下关于牛顿第二定律的解释是否准？[生成内容]”。这虽然成本高，但对关键知识领域是必要的。</li>
<li><strong>代码执行验证</strong>: 在沙箱环境中实际执行生成的代码，检查是否会抛出异常，输出是否符合预期。</li>
</ul>
</li>
<li>
<p><strong>风格与质量验证器 (L3)</strong>:</p>
<ul>
<li><strong>启发式规则</strong>: 检查是否存在低质量信号，如“我是一个语言模型...”、“根据我的知识...”，以及过度口语化、情绪化的表达。</li>
<li><strong>质量打分模型</strong>: 训练一个轻量级分类器，对生成文本的“教科书”程度、清晰度和知识密度进行打分（0-1分）。只有高于特定阈值（如0.85）的数据才会被接受。</li>
</ul>
</li>
</ol>
<blockquote>
<p><strong>Rule-of-thumb</strong>:
验证器应被设计成一个可插拔的流水线。对于成本高昂的验证（如裁判模型调用、代码执行），可以只应用于通过了廉价L1检查的数据上，以优化总体成本和效率。</p>
</blockquote>
<hr />
<h2 id="123">12.3 教授“思考”：难度爬坡、思维链与工具使用</h2>
<p>合成数据的核心目标是教会模型深层推理，而非表面模仿。</p>
<h4 id="1231-difficulty-curriculum">12.3.1 难度爬坡（Difficulty Curriculum）</h4>
<p>基于知识网格的依赖关系，我们可以设计一个从易到难的学习路径。</p>
<ul>
<li><strong>宏观层面</strong>: 训练初期，优先使用知识网格中没有前置依赖的“根节点”知识生成的数据。随着训练的进行，逐步解锁更高级的节点。</li>
<li><strong>微观层面</strong>: 在同一知识点内，通过程序化方式提升问题难度。例如，一个数学问题可以从2个变量逐步增加到5个变量；一个编程任务可以从实现单个函数，到实现一个包含多个方法和状态管理的类。</li>
</ul>
<h4 id="1232-chain-of-thought-cot">12.3.2 思维链（Chain-of-Thought, CoT）</h4>
<p>我们必须生成显式展示推理过程的数据。这让模型学习到一个通用的、可分解的问题解决框架。</p>
<p><strong>推荐的 CoT 格式</strong>:</p>
<div class="codehilite"><pre><span></span><code><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;question&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;如果一辆车以60公里/小时的速度行驶了45分钟，它行驶了多远？&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;reasoning_chain&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;step&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;thought&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;问题单位不统一，速度是公里/小时，时间是分钟。我需要先把时间单位转换成小时。&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;action&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;计算 45 分钟是多少小时。&quot;</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;step&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;thought&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1小时有60分钟，所以45分钟是 45/60 小时。&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;action&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;计算 45 / 60 = 0.75。所以时间是 0.75 小时。&quot;</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;step&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;thought&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;现在单位统一了。距离的计算公式是 距离 = 速度 × 时间。&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;action&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;计算 60 公里/小时 × 0.75 小时。&quot;</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;step&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;thought&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;60 × 0.75 = 45。&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;action&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;得出最终结果。&quot;</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">],</span>
<span class="w">  </span><span class="nt">&quot;final_answer&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;45公里&quot;</span>
<span class="p">}</span>
</code></pre></div>

<p><strong>关键点</strong>: 思维链不仅是步骤，更应该包含“元认知”——例如，识别问题、制定计划、修正错误（“哦，我刚才的计算错了，让我重新算一下”）。</p>
<h4 id="1233-tool-use-signals">12.3.3 工具使用信号（Tool-use Signals）</h4>
<p>对于我们的 VLA 和 Agent 目标，模型必须学会何时以及如何使用部工具。合成数据是训练这种能力的最直接方式。我们在数据中显式地嵌入工具调用的标记。</p>
<p><strong>格式化工具调用</strong>:</p>
<div class="codehilite"><pre><span></span><code>问题：请计算<span class="w"> </span>`sqrt(169)<span class="w"> </span>*<span class="w"> </span>log10(1000)`<span class="w"> </span>的值。
思考：这个问题包含两部分计算，一个是开平方，一个是常用对数，我可以用计算器工具来精确计算。
<span class="nt">&lt;tool_code&gt;</span>
print(calculator.sqrt(169))
<span class="nt">&lt;/tool_code&gt;</span>
<span class="nt">&lt;tool_output&gt;</span>
13.0
<span class="nt">&lt;/tool_output&gt;</span>
思考：`sqrt(169)`<span class="w"> </span>的结果是<span class="w"> </span>13.0。现在我来计算<span class="w"> </span>`log10(1000)`。
<span class="nt">&lt;tool_code&gt;</span>
print(calculator.log10(1000))
<span class="nt">&lt;/tool_code&gt;</span>
<span class="nt">&lt;tool_output&gt;</span>
3.0
<span class="nt">&lt;/tool_output&gt;</span>
思考：`log10(1000)`<span class="w"> </span>的结果是<span class="w"> </span>3.0。最后一步是把它们相乘。13.0<span class="w"> </span>*<span class="w"> </span>3.0<span class="w"> </span>=<span class="w"> </span>39.0。
最终答案是<span class="w"> </span>39.0。
</code></pre></div>

<p>这种格式化的数据直接教会了模型在自回归生成过程中，何时暂停文本生成，切换到工具调用模式，并如何将工具返回的结果整合回后续的推理中。</p>
<hr />
<h2 id="124">12.4 生成经济学与规模化</h2>
<p>大规模生成合成数据本身就是一个昂贵的计任务，需要精细的成本管理。</p>
<ul>
<li><strong>生成模型的选择</strong>: 不一定需要最强大的模型（如 GPT-4）来生成所有数据。可以采用级联策略：使用高性能模型生成高质量的“种子”数据，然后用这些种子数据微调一个更小、更经济的模型（例如，一个 7B 或 13B 的模型），让这个小模型来执行大规模的生产任务。</li>
<li><strong>成本效益分析</strong>: 必须量化合成数据的投入产出比。一个关键指标是“认知增益/美元”。即，花费1美元在合成数据生成上，能在多大程度上提升模型在关键评测（如 GSM8K, HumanEval）上的表现，并与简单地多购买1美元的真实数据训练时长进行对比。</li>
<li><strong>基础设施</strong>: 搭建一个稳健的分布式任务调度系统（如基于 Airflow, Kubeflow Pipelines, Ray）来管理数百万个生成任务。这包括任务分发、依赖管理、失败重试、结果收集和验证。这本身就是一个重要的 MLOps 工程。</li>
</ul>
<hr />
<h2 id="125">12.5 防护与纯净：数据去污协议</h2>
<p>合成数据可能无意中“背诵”或“模仿”出评测集中的内容，导致评测分数虚高，这是一种致命的科学错误。我们必须执行严格的数据去污协议。</p>
<p><strong>协议步骤</strong>:</p>
<ol>
<li><strong>建立“剧毒”禁区</strong>: 将所有已知和潜在的评测数据集（公开基准、内部评测集）隔离，建立严格的访问控制。任何参与数据生成流程的组件和人员，原则上都不能接触这些数据。</li>
<li><strong>多层过滤机制</strong>:<ul>
<li><strong>精确匹配</strong>: 使用哈希（如 SHA-256）快速排除与评测集样本完全一致的生成数据。</li>
<li><strong>N-gram 重叠</strong>: 计算生成样本与所有评测样本之间的 n-gram (n=8, 13) 重叠率。任何重叠率超过阈值（如 20%）的样本都应被标记或丢弃。</li>
<li><strong>向量相似度</strong>: 将生成数据和评测数据嵌入到同一个向量空间（例如，使用一个预训练的句子编码器）。使用高效的向量检索引擎（如 FAISS, ScaNN）查找近邻。任何与评测样本余弦相似度高于阈值（如 0.95）的生成数据都必须被丢弃。</li>
</ul>
</li>
<li><strong>对真实数据去重</strong>: 合成数据也可能与我们采集的真实数据重复。同样的去重流程也应应用于合成数据与真实数据集之间，以确保合成数据的“新颖性”和增量价值。</li>
<li><strong>持续审计与红队演练</strong>: 定期进行人工审计，抽查最终进入训练集的数据。组织“红队”，主动尝试构造能够污染评测集的合成数据，以测试和加固去污协议的鲁棒性。</li>
</ol>
<blockquote>
<p><strong>Rule-of-thumb</strong>:
数据去污不是一次性的任务，而是一个贯穿始终的流程。对数据纯净性的投资，是对模型能力真实评估的根本保障。宁可错杀一千，不可放过一个污染样本。</p>
</blockquote>
<hr />
<h2 id="_2">本章小结</h2>
<p>本章深入探讨了如何通过合成“教科书”式的数据，为大模型预训练注入高质量的“认知燃料”。这不仅是对海量网络数据的有效补充，更是通往更高层级理和智能的战略路径。</p>
<ul>
<li><strong>蓝图先行</strong>: 成功的合成数据项目始于一个结构化的<strong>知识网格</strong>和可执行的<strong>课程蓝图</strong>，这是保证内容系统性和覆盖性的前提。</li>
<li><strong>质量生命线</strong>: <strong>生成-验证</strong>闭环是数据质量的生命线。强大的模板设计、多层次的自动化验证器，共同构成了一个可扩展、可信赖的数据工厂。</li>
<li><strong>学习过程而非结果</strong>: 通过<strong>思维链</strong>和<strong>工具使用</strong>信号，我们让模型学习解决问题的通用方法论，这比单纯记忆知识点更有价值。</li>
<li><strong>成本与纯净</strong>: 合成数据项目需要精明的<strong>经济学考量</strong>和<strong>规模化工程</strong>支持。同时，必须执行严格的<strong>数据去污协议</strong>，以捍卫评测的公正性，这是整个项目的科学基石。</li>
</ul>
<hr />
<h2 id="gotchas">常见陷阱与错误 (Gotchas)</h2>
<ol>
<li>
<p><strong>陷阱：生成模型的“风格过拟合”。</strong></p>
<ul>
<li><strong>问题</strong>: 如果所有合成数据都来自同一个生成模型和少数几个模板，预训练模型可能会过拟合这种单一、干净、结构化的“合成风格”，导致其在处理真实世界 messy、口语化的输入时表现脆弱。</li>
<li><strong>调试与规避</strong>: 引入多样化的生成模板；使用多个不同的生成模型（甚至不同公司的模型）来增加风格多样性；在生成指令中有意识地要求不同的语气和格式；确保合成数据只占总体数据的一部分，与真实数据充分混合。</li>
</ul>
</li>
<li>
<p><strong>陷阱：生成模型的“知识漂移”。</strong></p>
<ul>
<li><strong>问题</strong>: 用来生成数据的模型本身会随着时间更新和迭代。新版本的模型可能对同一个 Prompt 产生与旧版本风格或内容有显著差异的输出，导致合成数据分布发生意外的漂移。</li>
<li><strong>调试与规避</strong>: 对生成模型进行严格的版本锁定。任何模型升级都需要经过小规模 A/B 测试，评估其对数据分布的影响。所有生成数据必须附带元数据，标明其由哪个模型的哪个版本生成。</li>
</ul>
</li>
<li>
<p><strong>陷阱：视了合成数据的“负样本”。</strong></p>
<ul>
<li><strong>问题</strong>: 如果只生成正确、完美的“教科书”答案和推理过程，模型将缺乏对错误和陷阱的辨识能力。</li>
<li><strong>调试与规避</strong>: 有意识地生成一些“常见错误”的例子。例如，在代码生成中，故意引入一些经典的 off-by-one 错误或逻辑漏洞，并让模型学习识别、解释并修复它们。这对于训练模型的批判性思维和调试能力至关重要。</li>
</ul>
</li>
<li>
<p><strong>陷阱：数据去污流程的计算瓶颈。</strong></p>
<ul>
<li><strong>问题</strong>: 对 TB 级的合成数据与 TB 级的真实/评测数据进行两两比对，计算成本极高，很容易成为整个数据管道的瓶颈。</li>
<li><strong>调试与规避</strong>: 采用多阶段、由粗到细的去重策略。先用廉价的 MinHash 或 LSH（局部敏感哈希）进行快速筛选，大幅减少需要进行昂贵向量相似度计算的候选对。将此过程工程化，使用分布式计算框架（如 Spark）来加速。</li>
</ul>
</li>
</ol>
            </article>
            
            <nav class="page-nav"><a href="chapter11.html" class="nav-link prev">← 第 11 章 过滤与去脏：fastText 与小模型策略库</a><a href="chapter13.html" class="nav-link next">第十三章 合成数据 II：音频与语音 →</a></nav>
        </main>
    </div>
</body>
</html>